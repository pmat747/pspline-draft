%%%%%%%%%%%%%%%%%%
%%% R packages %%%
%%%%%%%%%%%%%%%%%%

@Manual{Edwards:bsplinePsd:2018,
	title  = {bsplinePsd: Bayesian nonparametric spectral density estimation using b-spline priors},
	author = {Matthew C. Edwards and Renate Meyer and Nelson Christensen},
	year   = {2018},
	note   = {{R package version 0.6.0}},
	url    =  {https://CRAN.R-project.org/package=bsplinePsd},
 }

 @Manual{fda,
  title  = {fda: Functional Data Analysis},
  author = {J. O. Ramsay and Hadley Wickham and Spencer Graves and Giles Hooker},
  year   = {2020},
  note   = {R package version 2.4.8.1},
  url    = {https://CRAN.R-project.org/package=fda},
}

@Manual{psplinepackage,
	title  = {psplinePsd: P-splines for spectral density estimation},
	author = {Patricio Maturana-Russel and Renate Meyer},
	year   = {2020},
	url    = {https://github.com/pmat747/psplinePsd},
 }


%%%%%%%%%
%%% B %%%
%%%%%%%%%

@article{Lang:2004,
	author = {Stefan Lang and Andreas Brezger},
	title = {Bayesian P-Splines},
	journal = {Journal of Computational and Graphical Statistics},
	volume = {13},
	number = {1},
	pages = {183-212},
	year  = {2004},
	publisher = {Taylor & Francis},
	doi = {10.1198/1061860043010},
	URL = {https://doi.org/10.1198/1061860043010},
	eprint = {https://doi.org/10.1198/1061860043010}
}

@article{Bremhorst:2016,
	title = "Flexible estimation in cure survival models using {B}ayesian P-splines",
	journal = "Computational Statistics \& Data Analysis",
	volume = "93",
	pages = "270 - 284",
	year = "2016",
	issn = "0167-9473",
	doi = "https://doi.org/10.1016/j.csda.2014.05.009",
	url = "http://www.sciencedirect.com/science/article/pii/S0167947314001492",
	author = "Vincent Bremhorst and Philippe Lambert",
	keywords = "Bayesian P-splines, Cox model, Cure fraction, Promotion time model, Survival analysis",
	abstract = "In the analysis of survival data, it is usually assumed that any unit will experience the event of interest if it is observed for a sufficiently long time. However, it can be explicitly assumed that an unknown proportion of the population under study will never experience the monitored event. The promotion time model, which has a biological motivation, is one of the survival models taking this feature into account. The promotion time model assumes that the failure time of each subject is generated by the minimum of N independent latent event times with a common distribution independent of N. An extension which allows the covariates to influence simultaneously the probability of being cured and the latent distribution is presented. The latent distribution is estimated using a flexible Cox proportional hazard model where the logarithm of the baseline hazard function is specified using Bayesian P-splines. Introducing covariates in the latent distribution implies that the population hazard function might not have a proportional hazard structure. However, the use of P-splines provides a smooth estimation of the population hazard ratio over time. The identification issues of the model are discussed and a restricted use of the model when the follow-up of the study is not sufficiently long is proposed. The accuracy of our methodology is evaluated through a simulation study and the model is illustrated on data from a Melanoma clinical trial."
}

@book{Brockwell:1986,
	author = {Brockwell, Peter J and Davis, Richard A},
	title = {Time Series: Theory and Methods},
	year = {1991},
	isbn = {978-0-387-97429-3},
	publisher = {Springer-Verlag New York},
	address = {New York, USA},
	edition   = {2},
	doi = {10.1007/978-1-4419-0320-4},
	url = {https://doi.org/10.1007/978-1-4419-0320-4}
} 

%%%%%%%%%
%%% C %%%
%%%%%%%%%

@article{Cadonna2017,
	title={Bayesian mixture modeling for spectral density estimation},
	author={Cadonna, A. and Kottas, A. and Prado, R.},
	journal={Statistics \& Probability Letters},
	volume={125},
	pages={189--195},
	year={2017},
	issn = {0167-7152},
	doi = {https://doi.org/10.1016/j.spl.2017.02.008},
	url = {http://www.sciencedirect.com/science/article/pii/S0167715217300573}
}

@article{Cart:1997,
	author = {C. K. Carter and R. Kohn},
	title = {Semiparametric {B}ayesian inference for time series with mixed spectra},
	journal = {Journal of the Royal Statistical Society, Series B},
	year = {1997},
	volume = {59},
	number = {1},
	doi = {10.1111/1467-9868.00067},
	URL ={https://doi.org/10.1111/1467-9868.00067},
	pages = {255-268}
}

@article{Choudhuri:2004,
	author = {Nidhan Choudhuri and Subhashis Ghosal and Anindya Roy},
	title = {Bayesian Estimation of the Spectral Density of a Time Series},
	journal = {Journal of the American Statistical Association},
	volume = {99},
	number = {468},
	pages = {1050-1059},
	year  = {2004},
	publisher = {Taylor & Francis},
	doi = {10.1198/016214504000000557},
	URL = {https://doi.org/10.1198/016214504000000557},
	eprint = {https://doi.org/10.1198/016214504000000557}
}

%%%%%%%%%
%%% E %%%
%%%%%%%%%


@article{Edwards2019,
pages = {67--78},
volume = {29},
publisher = {Springer US},
number = {1},
year = {2019},
title = {Bayesian nonparametric spectral density estimation using B-spline priors},
language = {eng},
address = {New York},
author = {Edwards, Matthew and Meyer, Renate and Christensen, Nelson},
keywords = {B-spline prior ; Bernstein polynomial prior ; Whittle likelihood ; Spectral density estimation ; Bayesian nonparametrics ; LIGO ; Gravitational waves ; Sunspot cycle},
issn = {0960-3174},
abstract = {We present a new Bayesian nonparametric approach to estimating the spectral density of a stationary time series. A nonparametric prior based on a mixture of B-spline distributions is specified and can be regarded as a generalization of the Bernstein polynomial prior of Petrone (Scand J Stat 26:373–393, 1999a; Can J Stat 27:105–126, 1999b) and Choudhuri et al. (J Am Stat Assoc 99(468):1050–1059, 2004). Whittle’s likelihood approximation is used to obtain the pseudo-posterior distribution. This method allows for a data-driven choice of the number of mixture components and the location of knots. Posterior samples are obtained using a Metropolis-within-Gibbs Markov chain Monte Carlo algorithm, and mixing is improved using parallel tempering. We conduct a simulation study to demonstrate that for complicated spectral densities, the B-spline prior provides more accurate Monte Carlo estimates in terms of $$L_1$$ L 1 -error and uniform coverage probabilities than the Bernstein polynomial prior. We apply the algorithm to annual mean sunspot data to estimate the solar cycle. Finally, we demonstrate the algorithm’s ability to estimate a spectral density with sharp features, using real gravitational wave detector data from LIGO’s sixth science run, recoloured to match the Advanced LIGO target sensitivity.},
journal = {Statistics and Computing},
URL ={https://doi.org/10.1007/s11222-017-9796-9}
}

@article{Eilers:1996,
	author = "Eilers, Paul H. C. and Marx, Brian D.",
	doi = "10.1214/ss/1038425655",
	fjournal = "Statistical Science",
	journal = "Statist. Sci.",
	month = "05",
	number = "2",
	pages = "89--121",
	publisher = "The Institute of Mathematical Statistics",
	title = "Flexible smoothing with B -splines and penalties",
	url = "https://doi.org/10.1214/ss/1038425655",
	volume = "11",
	year = "1996"
}


@Article{Eilers2015,
	author={Paul H. C. Eilers and Brian D. Marx and Mar{\'i}a Durb{\'a}n},
	title={Twenty years of P-splines},
	journal={SORT: statistics and operations research transactions},
	volume={39},
	number={2},
	url={http://hdl.handle.net/2117/88526},
	issn={1696-2281},
	year={2015}
}

%%%%%%%%%
%%% G %%%
%%%%%%%%%

@article{Gangopadhyay:1999,
	title = "Estimation of spectral density of a stationary time series via an asymptotic representation of the periodogram",
	journal = "Journal of Statistical Planning and Inference",
	volume = "75",
	number = "2",
	pages = "281 - 290",
	year = "1999",
	issn = "0378-3758",
	doi = "https://doi.org/10.1016/S0378-3758(98)00148-7",
	url = "http://www.sciencedirect.com/science/article/pii/S0378375898001487",
	author = "A.K. Gangopadhyay and B.K. Mallick and D.G.T. Denison",
	keywords = "Spectral density estimation, Reversible jump MCMC, Piecewise polynomial",
	abstract = "In this paper, we discuss two estimators of the spectral density, which are based on certain asymptotic representations of the periodogram of a stationary time series. These asymptotic representations lead to local linear models. The parameters of the linear model are estimated via ordinary least squares for the first estimator, and via Bayesian approach involving reversible jump MCMC method for the second estimator. These techniques are successful in providing smooth estimators without sacrificing the important characteristics of the spectral densities such as peaks and troughs."
}

@article{Green:1995,
	author = {Green, Peter J.},
	title = "{Reversible jump Markov chain Monte Carlo computation and Bayesian model determination}",
	journal = {Biometrika},
	volume = {82},
	number = {4},
	pages = {711-732},
	year = {1995},
	month = {12},
	abstract = "{Markov chain Monte Carlo methods for Bayesian computation have until recently been restricted to problems where the joint distribution of all variables has a density with respect to some fixed standard underlying measure. They have therefore not been available for application to Bayesian model determination, where the dimensionality of the parameter vector is typically not fixed. This paper proposes a new framework for the construction of reversible Markov chain samplers that jump between parameter subspaces of differing dimensionality, which is flexible and entirely constructive. It should therefore have wide applicability in model determination problems. The methodology is illustrated with applications to multiple change-point analysis in one and two dimensions, and to a Bayesian comparison of binomial experiments.}",
	issn = {0006-3444},
	doi = {10.1093/biomet/82.4.711},
	url = {https://dx.doi.org/10.1093/biomet/82.4.711},
	eprint = {http://oup.prod.sis.lan/biomet/article-pdf/82/4/711/699533/82-4-711.pdf},
}

%%%%%%%%%
%%% H %%%
%%%%%%%%%

@article{Huerta:1999,
	author = {G. Huerta and M. West},
	title = {Bayesian inference on periodicities and component spectral structure in time series},
	journal = {Journal of Time Series Analysis},
	year = {1999},
	volume = {20},
	number = {4},
	doi = {10.1111/1467-9892.00145},
	URL = { https://doi.org/10.1111/1467-9892.00145},
	pages = {401-416}
}

%%%%%%%%%
%%% J %%%
%%%%%%%%%

@article{Jullion:2007,
	title = "Robust specification of the roughness penalty prior distribution in spatially adaptive {B}ayesian P-splines models",
	journal = "Computational Statistics \& Data Analysis",
	volume = "51",
	number = "5",
	pages = "2542 - 2558",
	year = "2007",
	issn = "0167-9473",
	doi = "https://doi.org/10.1016/j.csda.2006.09.027",
	url = "http://www.sciencedirect.com/science/article/pii/S0167947306003549",
	author = "Astrid Jullion and Philippe Lambert",
	keywords = "Bayesian P-splines, Adaptive penalties, Prior specification, Markov chain Monte Carlo",
	abstract = "The potential important role of the prior distribution of the roughness penalty parameter in the resulting smoothness of Bayesian P-splines models is considered. The recommended specification for that distribution yields models that can lack flexibility in specific circumstances. In such instances, these are shown to correspond to a frequentist P-splines model with a predefined and severe roughness penalty parameter, an obviously undesirable feature. It is shown that the specification of a hyperprior distribution for one parameter of that prior distribution provides the desired flexibility. Alternatively, a mixture prior can also be used. An extension of these two models by enabling adaptive penalties is provided. The posterior of all the proposed models can be quickly explored using the convenient Gibbs sampler."
}

%%%%%%%%%
%%% k %%%
%%%%%%%%%

@article{Kauermann2011,
	ISSN = {00063444},
	URL = {http://www.jstor.org/stable/29777177},
	abstract = {A number of criteria exist to select the penalty in penalized spline regression, but the selection of the number of spline basis functions has received much less attention in the literature. We propose a likelihood—based criterion to select the number of basis functions in penalized spline regression. The criterion is easy to apply and we describe its theoretical and practical properties.},
	author = {G{\"o}ran Kauermann and Jean D. Opsomer},
	journal = {Biometrika},
	number = {1},
	pages = {225--230},
	publisher = {Biometrika Trust},
	title = {Data-driven selection of the spline dimension in penalized spline regression},
	volume = {98},
	year = {2011}
}

@article{Kirch:2018,
	author = "Kirch, Claudia and Edwards, Matthew C. and Meier, Alexander and Meyer, Renate",
	doi = "10.1214/18-BA1126",
	firstAvailable = "2018-10-30T02:15:47Z",
	fjournal = "Bayesian Analysis",
	journal = "Bayesian Anal.",
	note = "Advance publication",
	publisher = "International Society for Bayesian Analysis",
	title = "Beyond {W}hittle: Nonparametric Correction of a Parametric Likelihood with a Focus on {B}ayesian Time Series Analysis",
	url = "https://doi.org/10.1214/18-BA1126",
	page = {1-37},
	year = "2018"
}



%%%%%%%%%
%%% L %%%
%%%%%%%%%

@article{Lambert:2007,
	title = "Archimedean copula estimation using {B}ayesian splines smoothing techniques",
	journal = "Computational Statistics \& Data Analysis",
	volume = "51",
	number = "12",
	pages = "6307 - 6320",
	year = "2007",
	issn = "0167-9473",
	doi = "https://doi.org/10.1016/j.csda.2007.01.018",
	url = "http://www.sciencedirect.com/science/article/pii/S0167947307000217",
	author = "Philippe Lambert",
	keywords = "Archimedean copula, Bayesian P-splines, Markov chains Monte Carlo, Monotonicity and convexity constraints",
	abstract = "Copulas enable to specify multivariate distributions with given marginals. Various parametric proposals were made in the literature for these quantities, mainly in the bivariate case. They can be systematically derived from multivariate distributions with known marginals, yielding e.g. the normal and the Student copulas. Alternatively, one can restrict his/her interest to a sub-family of copulas named Archimedean. They are characterized by a strictly decreasing convex function on (0,1) which tends to +∞ at 0 (when strict) and which is 0 at 1. A ratio approximation of the generator and of its first derivative using B-splines is proposed and the associated parameters estimated using Markov chains Monte Carlo methods. The estimation is reasonably quick. The fitted generator is smooth and parametric. The generated chain(s) can be used to build “credible envelopes” for the above ratio function and derived quantities such as Kendall's tau, posterior predictive probabilities, etc. Parameters associated to parametric models for the marginals can be estimated jointly with the copula parameters. This is an interesting alternative to the popular two-step procedure which assumes that the regression parameters are fixed known quantities when it comes to copula parameter(s) estimation. A simulation study is performed to evaluate the approach. The practical utility of the method is illustrated by a basic analysis of the dependence structure underlying the diastolic and the systolic blood pressures in male subjects."
}

@article{Likhachev2017,
	title = {Selecting the right number of knots for B-spline parameterization of the dielectric functions in spectroscopic ellipsometry data analysis},
	journal = {Thin Solid Films},
	volume = {636},
	pages = {519 - 526},
	year = {2017},
	issn = {0040-6090},
	doi = {https://doi.org/10.1016/j.tsf.2017.06.056},
	url = {http://www.sciencedirect.com/science/article/pii/S0040609017304911},
	author = {D.V. Likhachev},
	keywords = {Dielectric function, Parameterization, B-splines, Information criteria, Data analysis, Spectroscopic ellipsometry},
	abstract = {B-spline representation of the dielectric functions provides many theoretical and practical benefits for material modeling in spectroscopic ellipsometry. However, the number of knots (and their locations, in general) defines actual performance of B-splines in ellipsometric data analysis. On the one hand, too large number of knots can result in serious overfitting of the experimental data. On the other hand, this number should be sufficient to fit all essential spectral features. Selection of the right number of knots is, in practice, a very subjective and empirically-driven task. In this paper, we discuss the choice of the number of knots utilizing three well-established versions of statistical information criteria in form of Akaike, corrected Akaike and Bayesian Information Criteria (AIC, AICc and BIC, respectively). The criteria establish a compromise between over- and underfitting of experimental data and allow formalized selection of the right number of knots. Effectiveness of the proposed methodology is illustrated using a few real-data examples.}
}

%%%%%%%%%
%%% P %%%
%%%%%%%%%

@article{Pensky:2007,
	URL = {http://www3.stat.sinica.edu.tw/statistica/j17n2/j17n210/j17n210.html},
	abstract = {The problem of estimating the log-spectrum of a stationary time series by Bayesian shrinkage of empirical wavelet coefficients is studied. A model in the wavelet domain that accounts for distributional properties of the log-periodogram at levels of fine detail and approximate normality at coarse levels in the wavelet decomposition, is proposed. The smoothing procedure, called BAMS-LP (Bayesian Adaptive Multiscale Shrinker of Log-Periodogram), ensures that the reconstructed log-spectrum is sufficiently noise-free. It is also shown that the resulting Bayes estimators are asymptotically optimal (in the mean-squared error sense).},
	author = {Pensky, Marianna and Vidakovic, Brani and and De Canditiis, Daniela},
	journal = {Statistica Sinica},
	number = {},
	pages = {635--666},
	publisher = {},
	title = {Bayesian decision theoretic scale-adaptive estimation of a log-spectral density},
	volume = {17},
	year = {2007}
}

@article{Perron:2001,
	ISSN = {0006341X, 15410420},
	URL = {http://www.jstor.org/stable/3068361},
	abstract = {Nonparametric modeling is an indispensable tool in many applications and its formulation in an hierarchical Bayesian context, using the entire posterior distribution rather than particular expectations, increases its flexibility. In this article, the focus is on nonparametric estimation through a mixture of triangular distributions. The optimality of this methodology is addressed and bounds on the accuracy of this approximation are derived. Although our approach is more widely applicable, we focus for simplicity on estimation of a monotone nondecreasing regression on [0, 1] with additive error, effectively approximating the function of interest by a function having a piecewise linear derivative. Computationally accessible methods of estimation are described through an amalgamation of existing Markov chain Monte Carlo algorithms. Simulations and examples illustrate the approach.},
	author = {F. Perron and K. Mengersen},
	journal = {Biometrics},
	number = {2},
	pages = {518--528},
	publisher = {[Wiley, International Biometric Society]},
	title = {Bayesian Nonparametric Modeling Using Mixtures of Triangular Distributions},
	volume = {57},
	year = {2001}
}



@article{Petrone:1999a,
	author = {Petrone, Sonia},
	title = {Random {B}ernstein Polynomials},
	journal = {Scandinavian Journal of Statistics},
	volume = {26},
	number = {3},
	pages = {373-393},
	keywords = {Bayesian non-parametric inference, Bernstein polynomials, Dirichlet process, Markov chain Monte Carlo, random distribution functions},
	doi = {10.1111/1467-9469.00155},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9469.00155},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9469.00155},
abstract = {Random Bernstein polynomials which are also probability distribution functions on the closed unit interval are studied. The probability law of a Bernstein polynomial so defined provides a novel prior on the space of distribution functions on [0, 1] which has full support and can easily select absolutely continuous distribution functions with a continuous and smooth derivative. In particular, the Bernstein polynomial which approximates a Dirichlet process is studied. This may be of interest in Bayesian non-parametric inference. In the second part of the paper, we study the posterior from a “Bernstein–Dirichlet” prior and suggest a hybrid Monte Carlo approximation of it. The proposed algorithm has some aspects of novelty since the problem under examination has a “changing dimension” parameter space.},
	year = {1999}
}

@article{Petrone:199b,
	ISSN = {03195724},
	URL = {http://www.jstor.org/stable/3315494},
	abstract = {We propose a Bayesian nonparametric procedure for density estimation, for data in a closed, bounded interval, say [0, 1]. To this aim, we use a prior based on Bernstein polynomials. This corresponds to expressing the density of the data as a mixture of given beta densities, with random weights and a random number of components. The density estimate is then obtained as the corresponding predictive density function. Comparison with classical and Bayesian kernel estimates is provided. The proposed procedure is illustrated in an example; an MCMC algorithm for approximating the estimate is also discussed. /// L'auteure propose une procédure bayésienne non paramétrique pour l'estimation de la densité à partir de données appartenant à un intervalle fermé et borné tel que l'intervalle [0, 1]. Dans ce but, elle fait appel à une loi a priori construite à partir des polynômes de Bernstein. Ceci revient à exprimer la densité des observations par un mélange d'un nombre aléatoire de densités bêta particulières affectées de poids aléatoires. C'est alors la densité prédictive correspondante qui sert d'estimateur. L'auteure compare celui-ci aux estimations à noyau classiques et de Bayes. Cette technique d'estimation est illustrée à l'aide d'un exemple et l'auteure montre comment approximer la solution au moyen d'un algorithme de Monte-Carlo à chaîne de Markov.},
	author = {Sonia Petrone},
	journal = {The Canadian Journal of Statistics / La Revue Canadienne de Statistique},
	number = {1},
	pages = {105--126},
	publisher = {[Statistical Society of Canada, Wiley]},
	title = {Bayesian Density Estimation Using {B}ernstein Polynomials},
	volume = {27},
	year = {1999}
}

@article{Polson:2013,
	author = { Nicholas G.   Polson  and  James G.   Scott  and  Jesse   Windle },
	title = {Bayesian Inference for Logistic Models Using {P}\'olya–{G}amma Latent Variables},
	journal = {Journal of the American Statistical Association},
	volume = {108},
	number = {504},
	pages = {1339-1349},
	year  = {2013},
	publisher = {Taylor & Francis},
	doi = {10.1080/01621459.2013.829001},
	URL = {https://doi.org/10.1080/01621459.2013.829001},
	eprint = {https://doi.org/10.1080/01621459.2013.829001}
}

%%%%%%%%%
%%% R %%%
%%%%%%%%%

@article{Rosen:2012,
issn = {0162-1459},
abstract = {We propose a method for analyzing possibly nonstationary time series by adaptively dividing the time series into an unknown but finite number of segments and estimating the corresponding local spectra by smoothing splines. The model is formulated in a Bayesian framework, and the estimation relies on reversible jump Markov chain Monte Carlo (RJMCMC) methods. For a given segmentation of the time series, the likelihood function is approximated via a product of local Whittle likelihoods. Thus, no parametric assumption is made about the process underlying the time series. The number and lengths of the segments are assumed unknown and may change from one MCMC iteration to another. The frequentist properties of the method are investigated by simulation, and applications to electroencephalogram and the El Niño Southern Oscillation phenomenon are described in detail.},
journal = {Journal of the American Statistical Association},
pages = {1575--1589},
volume = {107},
publisher = {Taylor & Francis Group},
number = {500},
year = {2012},
title = {AdaptSPEC: Adaptive Spectral Estimation for Nonstationary Time Series},
language = {eng},
author = {Rosen, Ori and Wood, Sally and Stoffer, David S.},
keywords = {Electroencephalogram ; El Niño Southern Oscillation ; Locally Stationary Time Series ; Reversible Jump Markov Chain Monte Carlo ; Whittle Likelihood.},
 doi = {10.1080/01621459.2012.716340},
    url = {https://doi.org/10.1080/01621459.2012.716340}
}


@article{Rosen:2007,
    author = {Rosen, Ori and Stoffer, David S.},
    title = "{Automatic estimation of multivariate spectra via smoothing splines}",
    journal = {Biometrika},
    volume = {94},
    number = {2},
    pages = {335-345},
    year = {2007},
    month = {02},
    abstract = "{The classical method for estimating the spectral density of a multivariate time series is first to calculate the periodogram, and then to smooth it to obtain a consistent estimator. Typically, to ensure the estimate is positive definite, all the elements of the periodogram are smoothed the same way. There are, however, many situations for which different components of the spectral matrix have different degrees of smoothness. We propose a Bayesian approach that uses Markov chain Monte Carlo techniques to fit smoothing splines to each component, real and imaginary, of the Cholesky decomposition of the periodogram matrix. The spectral estimator is then obtained by reconstructing the spectral estimator from the smoothed Cholesky decomposition components. Our technique produces an automatically smoothed spectral matrix estimator along with samples from the posterior distributions of the parameters to facilitate inference.}",
    issn = {0006-3444},
    doi = {10.1093/biomet/asm022},
    url = {https://doi.org/10.1093/biomet/asm022},
    eprint = {http://oup.prod.sis.lan/biomet/article-pdf/94/2/335/599232/asm022.pdf},
}

@article{Ruppert2002,
	author = {David Ruppert},
	title = {Selecting the Number of Knots for Penalized Splines},
	journal = {Journal of Computational and Graphical Statistics},
	volume = {11},
	number = {4},
	pages = {735-757},
	year  = {2002},
	publisher = {Taylor & Francis},
	doi = {10.1198/106186002853},
	URL = {https://doi.org/10.1198/106186002853},
	eprint = {https://doi.org/10.1198/106186002853}
}

%%%%%%%%%
%%% S %%%
%%%%%%%%%

@article{Sethuraman:1994,
	added-at = {2009-09-10T14:36:22.000+0200},
	author = {Sethuraman, Jayaram},
	biburl = {https://www.bibsonomy.org/bibtex/2a7d63ad6a7d9bdcc2a6a1a3032863e7e/gregoryy},
	URL = {http://www3.stat.sinica.edu.tw/statistica/j4n2/j4n216/j4n216.htm},
	interhash = {4fcacac17864e008a908928ef7091141},
	intrahash = {a7d63ad6a7d9bdcc2a6a1a3032863e7e},
	journal = {Statistica Sinica},
	keywords = {imported},
	owner = {heinrich},
	pages = {639-650},
	timestamp = {2009-09-10T14:36:48.000+0200},
	title = {A constructive definition of {Dirichlet} priors},
	volume = {4},
	year = {1994}
}

@article{ShaoXiaofeng2007ASTf,
	issn = {00905364},
	abstract = {We consider asymptotic problems in spectral analysis of stationary causal processes. Limiting distributions of periodograms and smoothed periodogram spectral density estimates are obtained and applications to the spectral domain bootstrap are given. Instead of the commonly used strong mixing conditions, in our asymptotic spectral theory we impose conditions only involving (conditional) moments, which are easily verifiable for a variety of nonlinear time series.},
	journal = {The Annals of Statistics},
	pages = {1773--1801},
	volume = {35},
	publisher = {Institute of Mathematical Statistics},
	number = {4},
	year = {2007},
	title = {Asymptotic Spectral Theory for Nonlinear Time Series},
	language = {eng},
	url = {http://www.jstor.org/stable/25464559},
	author = {Shao, Xiaofeng and Wu, Wei Biao},
keywords = {Mathematics -- Pure mathematics -- Linear algebra ; Information science -- Data products -- Datasets ; Physical sciences -- Astronomy -- Astrophysics ; Physical sciences -- Physics -- Mechanics ; Mathematics -- Mathematical expressions -- Mathematical functions ; Mathematics -- Applied mathematics -- Statistics ; Mathematics -- Pure mathematics -- Probability theory ; Mathematics -- Pure mathematics -- Probability theory ; Information science -- Information analysis -- Data analysis ; Mathematics -- Applied mathematics -- Statistics ; Mathematics -- Pure mathematics -- Linear algebra ; Information science -- Data products -- Datasets ; Physical sciences -- Astronomy -- Astrophysics ; Physical sciences -- Physics -- Mechanics ; Mathematics -- Mathematical expressions -- Mathematical functions ; Mathematics -- Applied mathematics -- Statistics ; Mathematics -- Pure mathematics -- Probability theory ; Mathematics -- Pure mathematics -- Probability theory ; Information science -- Information analysis -- Data analysis ; Mathematics -- Applied mathematics -- Statistics},
}


%%%%%%%%%
%%% W %%%
%%%%%%%%%

@article{Whittle:1957,
	ISSN = {00359246},
	URL = {http://www.jstor.org/stable/2983994},
	abstract = {The difficulty in constructing smoothing formulae is to express quantitatively the type of smoothness one expects of the curve one is estimating. An argument is given in Sections 1 and 3 for formulating this "smoothness hypothesis" in terms of the properties of a population of curves of which the curve being estimated is a member. In equation (20) we obtain a solution for the matrix of optimum weighting coefficients in terms of certain "population moments" of the ordinates of the curve. Explicit formulae based on special assumptions are deduced in equations (34), (56)-(58). General information is gained on the way the optimum smoothing function and the variance of the smoothed estimate vary with the sample size and with the assumed degree of smoothness of the parent curve.},
	author = {P. Whittle},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	number = {1},
	pages = {38--63},
	publisher = {[Royal Statistical Society, Wiley]},
	title = {Curve and Periodogram Smoothing},
	volume = {19},
	year = {1957}
}

@article{Huerta:1999,
journal = {Journal of Time Series Analysis},
pages = {401--416},
volume = {20},
publisher = {Blackwell Publishers Ltd},
number = {4},
year = {1999},
title = {Bayesian Inference on Periodicities and Component Spectral Structure in Time Series},
address = {Oxford, UK and Boston, USA},
author = {Huerta, Gabriel and West, Mike},
}

@article{Rodriguez,
pages = {483--500},
volume = {29},
publisher = {Springer US},
number = {3},
title = {On the estimation of variance parameters in non-standard generalised linear mixed models: application to penalised smoothing},
language = {eng},
address = {New York},
author = {Rodríguez-Álvarez, María and Durban, Maria and Lee, Dae-Jin and Eilers, Paul},
keywords = {Generalised linear mixed models ; Generalised additive models ; Variance parameters ; Smoothing parameters ; REML ; Effective degrees of freedom},
issn = {0960-3174},
abstract = {We present a novel method for the estimation of variance parameters in generalised linear mixed models. The method has its roots in Harville (J Am Stat Assoc 72(358):320–338, 1977)’s work, but it is able to deal with models that have a precision matrix for the random effect vector that is linear in the inverse of the variance parameters (i.e., the precision parameters). We call the method SOP (separation of overlapping precision matrices). SOP is based on applying the method of successive approximations to easy-to-compute estimate updates of the variance parameters. These estimate updates have an appealing form: they are the ratio of a (weighted) sum of squares to a quantity related to effective degrees of freedom. We provide the sufficient and necessary conditions for these estimates to be strictly positive. An important application field of SOP is penalised regression estimation of models where multiple quadratic penalties act on the same regression coefficients. We discuss in detail two of those models: penalised splines for locally adaptive smoothness and for hierarchical curve data. Several data examples in these settings are presented.},
journal = {Statistics and Computing},
}


@article{WoodSimon2017Pwdb,
pages = {985--989},
volume = {27},
publisher = {Springer US},
number = {4},
year = {2017},
title = {P-splines with derivative based penalties and tensor product smoothing of unevenly distributed data},
language = {eng},
address = {New York},
author = {Wood, Simon},
keywords = {Reduced rank spline ; P-spline ; Smoothing spline ; Derivative penalty ; Tensor product smooth},
issn = {0960-3174},
abstract = {The P-splines of Eilers and Marx (Stat Sci 11:89–121, 1996) combine a B-spline basis with a discrete quadratic penalty on the basis coefficients, to produce a reduced rank spline like smoother. P-splines have three properties that make them very popular as reduced rank smoothers: (i) the basis and the penalty are sparse, enabling efficient computation, especially for Bayesian stochastic simulation; (ii) it is possible to flexibly ‘mix-and-match’ the order of B-spline basis and penalty, rather than the order of penalty controlling the order of the basis as in spline smoothing; (iii) it is very easy to set up the B-spline basis functions and penalties. The discrete penalties are somewhat less interpretable in terms of function shape than the traditional derivative based spline penalties, but tend towards penalties proportional to traditional spline penalties in the limit of large basis size. However part of the point of P-splines is not to use a large basis size. In addition the spline basis functions arise from solving functional optimization problems involving derivative based penalties, so moving to discrete penalties for smoothing may not always be desirable. The purpose of this note is to point out that the three properties of basis-penalty sparsity, mix-and-match penalization and ease of setup are readily obtainable with B-splines subject to derivative based penalization. The penalty setup typically requires a few lines of code, rather than the two lines typically required for P-splines, but this one off disadvantage seems to be the only one associated with using derivative based penalties. As an example application, it is shown how basis-penalty sparsity enables efficient computation with tensor product smoothers of scattered data.},
journal = {Statistics and Computing},
}

@article{Wood2017,
pages = {1071--1081},
volume = {73},
number = {4},
year = {2017},
title = {A generalized Fellner‐Schall method for smoothing parameter optimization with application to Tweedie location, scale and shape models},
author = {Wood, Simon N. and Fasiolo, Matteo},
keywords = {Fisheries ; Smoothing Parameter ; Reml ; Gamlss ; Sparse Additive Model},
issn = {0006-341X},
journal = {Biometrics},
}

@article{Meier2020,
volume = {175},
publisher = {Elsevier Inc},
year = {2020},
title = {Bayesian nonparametric analysis of multivariate time series: A matrix Gamma Process approach},
language = {eng},
author = {Meier, Alexander and Kirch, Claudia and Meyer, Renate},
keywords = {Bayesian Nonparametrics Completely Random Measures ; Spectral Density ; Stationary Multivariate Time Series ; Mathematics},
issn = {0047-259X},
abstract = {<p>Many Bayesian nonparametric approaches to multivariate time series rely on Whittle’s Likelihood, involving the second order structure of a stationary time series by means of its spectral density matrix. In this work, we model the spectral density matrix by means of random measures that are constructed in such a way that positive definiteness is ensured. This is in line with existing approaches for the univariate case, where the normalized spectral density is modeled similar to a probability density, e.g. with a Dirichlet process mixture of Beta densities. We present a related approach for multivariate time series, with matrix-valued mixture weights induced by a Hermitian positive definite Gamma process. The latter has not been considered in the literature, allows to include prior knowledge and possesses a series representation that will be used in MCMC methods. We establish posterior consistency and contraction rates and small sample performance of the proposed procedure is shown...},
journal = {Journal of Multivariate Analysis},
}

@article{Krivobokova,
pages = {443--459},
volume = {47},
publisher = {Springer-Verlag},
number = {3},
year = {2006},
title = {Estimating the term structure of interest rates using penalized splines},
language = {eng},
address = {Berlin/Heidelberg},
author = {Krivobokova, Tatyana and Kauermann, Göran and Archontakis, Theofanis},
keywords = {Interest Rates;},
issn = {0932-5026},
journal = {Statistical Papers},
}

@article{Wegener,
pages = {557},
volume = {58},
publisher = {Springer},
number = {3},
year = {2017},
title = {Forecasting in nonlinear univariate time series using penalized splines.(Report)},
language = {eng},
author = {Wegener, Michael and Kauermann, Goran},
keywords = {Splines ; Mathematical Models ; Time Series ; Economic Models ; Autoregressive Processes ; Forecasting ; Time Series ; Computer Simulation ; Convergence ; Economic Forecasting ; Time Series ; Penalized Splines ; Model Selection ; Eonia-Rate ; 62g08 ; 62m10;},
issn = {0932-5026},
abstract = {To access, purchase, authenticate, or subscribe to the full-text of this article, please visit this link: http://dx.doi.org/10.1007/s00362-015-0711-1 Byline: Michael Wegener (1), Goran Kauermann (2) Keywords: Time series; Penalized splines; Model selection; EONIA-rate; 62G08; 62M10 Abstract: In this article we discuss penalized splines for fitting and forecasting univariate nonlinear time series models. While penalized splines have been excessively used in smooth regression, their use in nonlinear time series models is less far developed. This paper focuses on univariate autoregressive processes and discuss different nonlinear (functional) time series models including parsimonious estimation and model selection ideas. Furthermore, in simulations and an application we show how this approach compares to common parametric nonlinear models. Author Affiliation: (1) Quantitative Products, DEKA Investment GmbH, Mainzer Landstrasse 16, Frankfurt (Main), Germany (2) Department of Statistics, Ludwigs-Maximilians-University Munich, Munich, Germany Article History: Registration Date: 27/08/2015 Received Date: 09/02/2015 Online Date: 15/09/2015},
journal = {Statistical Papers},
}

@article{Pawitan,
author = { Yudi   Pawitan  and  Finbarr   O'sullivan },
title = {Nonparametric Spectral Density Estimation Using Penalized Whittle Likelihood},
journal = {Journal of the American Statistical Association},
volume = {89},
number = {426},
pages = {600-610},
year  = {1994},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.1994.10476785},
URL = { https://doi.org/10.1080/01621459.1994.104767 },
eprint = {  https://doi.org/10.1080/01621459.1994.10476785}
}

@article{WandOrmerod,
pages = {179--198},
volume = {50},
publisher = {Blackwell Publishing Asia},
number = {2},
year = {2008},
title = {ON SEMIPARAMETRIC REGRESSION WITH {O'S}ULLIVAN PENALIZED SPLINES},
address = {Melbourne, Australia},
author = {Wand, M. P. and Ormerod, J. T.},
keywords = {Additive Models ; Markov Chain Monte Carlo ; Mixed Models ; P‐Splines ; Smoothing Splines},
issn = {1369-1473},
abstract = {An exposition on the use of O'Sullivan penalized splines in contemporary semiparametric regression, including mixed model and Bayesian formulations, is presented. O'Sullivan penalized splines are similar to P‐splines, but have the advantage of being a direct generalization of smoothing splines. Exact expressions for the O'Sullivan penalty matrix are obtained. Comparisons between the two types of splines reveal that O'Sullivan penalized splines more closely mimic the natural boundary behaviour of smoothing splines. Implementation in modern computing environments such as , and is discussed.},
journal = {Australian \& New Zealand Journal of Statistics}
}


