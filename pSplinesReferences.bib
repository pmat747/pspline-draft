%%%%%%%
%%% B %%%
%%%%%%%

@article{Lang:2004,
	author = {Stefan Lang and Andreas Brezger},
	title = {Bayesian P-Splines},
	journal = {Journal of Computational and Graphical Statistics},
	volume = {13},
	number = {1},
	pages = {183-212},
	year  = {2004},
	publisher = {Taylor & Francis},
	doi = {10.1198/1061860043010},
	URL = {https://doi.org/10.1198/1061860043010},
	eprint = {https://doi.org/10.1198/1061860043010}
}

@article{Bremhorst:2016,
	title = "Flexible estimation in cure survival models using Bayesian P-splines",
	journal = "Computational Statistics \& Data Analysis",
	volume = "93",
	pages = "270 - 284",
	year = "2016",
	issn = "0167-9473",
	doi = "https://doi.org/10.1016/j.csda.2014.05.009",
	url = "http://www.sciencedirect.com/science/article/pii/S0167947314001492",
	author = "Vincent Bremhorst and Philippe Lambert",
	keywords = "Bayesian P-splines, Cox model, Cure fraction, Promotion time model, Survival analysis",
	abstract = "In the analysis of survival data, it is usually assumed that any unit will experience the event of interest if it is observed for a sufficiently long time. However, it can be explicitly assumed that an unknown proportion of the population under study will never experience the monitored event. The promotion time model, which has a biological motivation, is one of the survival models taking this feature into account. The promotion time model assumes that the failure time of each subject is generated by the minimum of N independent latent event times with a common distribution independent of N. An extension which allows the covariates to influence simultaneously the probability of being cured and the latent distribution is presented. The latent distribution is estimated using a flexible Cox proportional hazard model where the logarithm of the baseline hazard function is specified using Bayesian P-splines. Introducing covariates in the latent distribution implies that the population hazard function might not have a proportional hazard structure. However, the use of P-splines provides a smooth estimation of the population hazard ratio over time. The identification issues of the model are discussed and a restricted use of the model when the follow-up of the study is not sufficiently long is proposed. The accuracy of our methodology is evaluated through a simulation study and the model is illustrated on data from a Melanoma clinical trial."
}

@book{Brockwell:1986,
	author = {Brockwell, Peter J and Davis, Richard A},
	title = {Time Series: Theory and Methods},
	year = {1991},
	isbn = {978-0-387-97429-3},
	publisher = {Springer-Verlag New York},
	address = {New York, USA},
	edition   = {2},
	doi = {10.1007/978-1-4419-0320-4}
} 

%%%%%%%
%%% C %%%
%%%%%%%

@article{Cart:1997,
	author = {C. K. Carter and R. Kohn},
	title = {Semiparametric Bayesian inference for time series with mixed spectra},
	journal = {Journal of the Royal Statistical Society, Series B},
	year = {1997},
	volume = {59},
	number = {1},
	doi = {10.1111/1467-9868.00067},
	URL ={https://doi.org/10.1111/1467-9868.00067},
	pages = {255-268}
}

@article{Choudhuri:2004,
	author = {Nidhan Choudhuri and Subhashis Ghosal and Anindya Roy},
	title = {Bayesian Estimation of the Spectral Density of a Time Series},
	journal = {Journal of the American Statistical Association},
	volume = {99},
	number = {468},
	pages = {1050-1059},
	year  = {2004},
	publisher = {Taylor & Francis},
	doi = {10.1198/016214504000000557},
	URL = {https://doi.org/10.1198/016214504000000557},
	eprint = {https://doi.org/10.1198/016214504000000557}
}

%%%%%%%
%%% E %%%
%%%%%%%

@Article{Edwards2018,
	author={Edwards, Matthew C. and Meyer, Renate and Christensen, Nelson},
	title={Bayesian nonparametric spectral density estimation using B-spline priors},
	journal={Statistics and Computing},
	year={2018},
	month={Jan},
	day={12},
	abstract={We present a new Bayesian nonparametric approach to estimating the spectral density of a stationary time series. A nonparametric prior based on a mixture of B-spline distributions is specified and can be regarded as a generalization of the Bernstein polynomial prior of Petrone (Scand J Stat 26:373--393, 1999a; Can J Stat 27:105--126, 1999b) and Choudhuri et al. (J Am Stat Assoc 99(468):1050--1059, 2004). Whittle's likelihood approximation is used to obtain the pseudo-posterior distribution. This method allows for a data-driven choice of the number of mixture components and the location of knots. Posterior samples are obtained using a Metropolis-within-Gibbs Markov chain Monte Carlo algorithm, and mixing is improved using parallel tempering. We conduct a simulation study to demonstrate that for complicated spectral densities, the B-spline prior provides more accurate Monte Carlo estimates in terms of {\$}{\$}L{\_}1{\$}{\$}L1-error and uniform coverage probabilities than the Bernstein polynomial prior. We apply the algorithm to annual mean sunspot data to estimate the solar cycle. Finally, we demonstrate the algorithm's ability to estimate a spectral density with sharp features, using real gravitational wave detector data from LIGO's sixth science run, recoloured to match the Advanced LIGO target sensitivity.},
	issn={1573-1375},
	doi={10.1007/s11222-017-9796-9},
	url={https://doi.org/10.1007/s11222-017-9796-9}
}

@Manual{Edwards:bsplinePsd:2018,
	title = {bsplinePsd: Bayesian Nonparametric Spectral Density Estimation Using B-Spline Priors},
	author = {Matthew C. Edwards and Renate Meyer and Nelson Christensen},
	year = {2018},
	note = {{R package version 0.6.0}},
	url = {https://CRAN.R-project.org/package=bsplinePsd},
  }


@Article{Eilers2015,
	author={Paul H. C. Eilers and Brian D. Marx and Mar{\'i}a Durb{\'a}n},
	title={Twenty years of P-splines},
	journal={SORT: statistics and operations research transactions},
	volume={39},
	number={2},
	url={http://hdl.handle.net/2117/88526},
	issn={1696-2281},
	year={2015}
}

%%%%%%%
%%% G %%%
%%%%%%%

@article{Gangopadhyay:1999,
	title = "Estimation of spectral density of a stationary time series via an asymptotic representation of the periodogram",
	journal = "Journal of Statistical Planning and Inference",
	volume = "75",
	number = "2",
	pages = "281 - 290",
	year = "1999",
	issn = "0378-3758",
	doi = "https://doi.org/10.1016/S0378-3758(98)00148-7",
	url = "http://www.sciencedirect.com/science/article/pii/S0378375898001487",
	author = "A.K. Gangopadhyay and B.K. Mallick and D.G.T. Denison",
	keywords = "Spectral density estimation, Reversible jump MCMC, Piecewise polynomial",
	abstract = "In this paper, we discuss two estimators of the spectral density, which are based on certain asymptotic representations of the periodogram of a stationary time series. These asymptotic representations lead to local linear models. The parameters of the linear model are estimated via ordinary least squares for the first estimator, and via Bayesian approach involving reversible jump MCMC method for the second estimator. These techniques are successful in providing smooth estimators without sacrificing the important characteristics of the spectral densities such as peaks and troughs."
}

@article{Green:1995,
	author = {Green, Peter J.},
	title = "{Reversible jump Markov chain Monte Carlo computation and Bayesian model determination}",
	journal = {Biometrika},
	volume = {82},
	number = {4},
	pages = {711-732},
	year = {1995},
	month = {12},
	abstract = "{Markov chain Monte Carlo methods for Bayesian computation have until recently been restricted to problems where the joint distribution of all variables has a density with respect to some fixed standard underlying measure. They have therefore not been available for application to Bayesian model determination, where the dimensionality of the parameter vector is typically not fixed. This paper proposes a new framework for the construction of reversible Markov chain samplers that jump between parameter subspaces of differing dimensionality, which is flexible and entirely constructive. It should therefore have wide applicability in model determination problems. The methodology is illustrated with applications to multiple change-point analysis in one and two dimensions, and to a Bayesian comparison of binomial experiments.}",
	issn = {0006-3444},
	doi = {10.1093/biomet/82.4.711},
	url = {https://dx.doi.org/10.1093/biomet/82.4.711},
	eprint = {http://oup.prod.sis.lan/biomet/article-pdf/82/4/711/699533/82-4-711.pdf},
}

%%%%%%%
%%% H %%%
%%%%%%%

@article{Huerta:1999,
	author = {G. Huerta and M. West},
	title = {Bayesian inference on periodicities and component spectral structure in time series},
	journal = {Journal of Time Series Analysis},
	year = {1999},
	volume = {20},
	number = {4},
	doi = {10.1111/1467-9892.00145},
	URL = { https://doi.org/10.1111/1467-9892.00145},
	pages = {401-416}
}

%%%%%%%
%%% J %%%
%%%%%%%

@article{Jullion:2007,
	title = "Robust specification of the roughness penalty prior distribution in spatially adaptive Bayesian P-splines models",
	journal = "Computational Statistics \& Data Analysis",
	volume = "51",
	number = "5",
	pages = "2542 - 2558",
	year = "2007",
	issn = "0167-9473",
	doi = "https://doi.org/10.1016/j.csda.2006.09.027",
	url = "http://www.sciencedirect.com/science/article/pii/S0167947306003549",
	author = "Astrid Jullion and Philippe Lambert",
	keywords = "Bayesian P-splines, Adaptive penalties, Prior specification, Markov chain Monte Carlo",
	abstract = "The potential important role of the prior distribution of the roughness penalty parameter in the resulting smoothness of Bayesian P-splines models is considered. The recommended specification for that distribution yields models that can lack flexibility in specific circumstances. In such instances, these are shown to correspond to a frequentist P-splines model with a predefined and severe roughness penalty parameter, an obviously undesirable feature. It is shown that the specification of a hyperprior distribution for one parameter of that prior distribution provides the desired flexibility. Alternatively, a mixture prior can also be used. An extension of these two models by enabling adaptive penalties is provided. The posterior of all the proposed models can be quickly explored using the convenient Gibbs sampler."
}

%%%%%%%
%%% k %%%
%%%%%%%

@article{Kauermann2011,
	ISSN = {00063444},
	URL = {http://www.jstor.org/stable/29777177},
	abstract = {A number of criteria exist to select the penalty in penalized spline regression, but the selection of the number of spline basis functions has received much less attention in the literature. We propose a likelihood—based criterion to select the number of basis functions in penalized spline regression. The criterion is easy to apply and we describe its theoretical and practical properties.},
	author = {G{\"o}ran Kauermann and Jean D. Opsomer},
	journal = {Biometrika},
	number = {1},
	pages = {225--230},
	publisher = {Biometrika Trust},
	title = {Data-driven selection of the spline dimension in penalized spline regression},
	volume = {98},
	year = {2011}
}

@article{Kirch:2018,
	author = "Kirch, Claudia and Edwards, Matthew C. and Meier, Alexander and Meyer, Renate",
	doi = "10.1214/18-BA1126",
	firstAvailable = "2018-10-30T02:15:47Z",
	fjournal = "Bayesian Analysis",
	journal = "Bayesian Anal.",
	note = "Advance publication",
	publisher = "International Society for Bayesian Analysis",
	title = "Beyond Whittle: Nonparametric Correction of a Parametric Likelihood with a Focus on Bayesian Time Series Analysis",
	url = "https://doi.org/10.1214/18-BA1126",
	page = {1-37},
	year = "2018"
}



%%%%%%%
%%% L %%%
%%%%%%%

@article{Lambert:2007,
	title = "Archimedean copula estimation using Bayesian splines smoothing techniques",
	journal = "Computational Statistics \& Data Analysis",
	volume = "51",
	number = "12",
	pages = "6307 - 6320",
	year = "2007",
	issn = "0167-9473",
	doi = "https://doi.org/10.1016/j.csda.2007.01.018",
	url = "http://www.sciencedirect.com/science/article/pii/S0167947307000217",
	author = "Philippe Lambert",
	keywords = "Archimedean copula, Bayesian P-splines, Markov chains Monte Carlo, Monotonicity and convexity constraints",
	abstract = "Copulas enable to specify multivariate distributions with given marginals. Various parametric proposals were made in the literature for these quantities, mainly in the bivariate case. They can be systematically derived from multivariate distributions with known marginals, yielding e.g. the normal and the Student copulas. Alternatively, one can restrict his/her interest to a sub-family of copulas named Archimedean. They are characterized by a strictly decreasing convex function on (0,1) which tends to +∞ at 0 (when strict) and which is 0 at 1. A ratio approximation of the generator and of its first derivative using B-splines is proposed and the associated parameters estimated using Markov chains Monte Carlo methods. The estimation is reasonably quick. The fitted generator is smooth and parametric. The generated chain(s) can be used to build “credible envelopes” for the above ratio function and derived quantities such as Kendall's tau, posterior predictive probabilities, etc. Parameters associated to parametric models for the marginals can be estimated jointly with the copula parameters. This is an interesting alternative to the popular two-step procedure which assumes that the regression parameters are fixed known quantities when it comes to copula parameter(s) estimation. A simulation study is performed to evaluate the approach. The practical utility of the method is illustrated by a basic analysis of the dependence structure underlying the diastolic and the systolic blood pressures in male subjects."
}

@article{Likhachev2017,
	title = {Selecting the right number of knots for B-spline parameterization of the dielectric functions in spectroscopic ellipsometry data analysis},
	journal = {Thin Solid Films},
	volume = {636},
	pages = {519 - 526},
	year = {2017},
	issn = {0040-6090},
	doi = {https://doi.org/10.1016/j.tsf.2017.06.056},
	url = {http://www.sciencedirect.com/science/article/pii/S0040609017304911},
	author = {D.V. Likhachev},
	keywords = {Dielectric function, Parameterization, B-splines, Information criteria, Data analysis, Spectroscopic ellipsometry},
	abstract = {B-spline representation of the dielectric functions provides many theoretical and practical benefits for material modeling in spectroscopic ellipsometry. However, the number of knots (and their locations, in general) defines actual performance of B-splines in ellipsometric data analysis. On the one hand, too large number of knots can result in serious overfitting of the experimental data. On the other hand, this number should be sufficient to fit all essential spectral features. Selection of the right number of knots is, in practice, a very subjective and empirically-driven task. In this paper, we discuss the choice of the number of knots utilizing three well-established versions of statistical information criteria in form of Akaike, corrected Akaike and Bayesian Information Criteria (AIC, AICc and BIC, respectively). The criteria establish a compromise between over- and underfitting of experimental data and allow formalized selection of the right number of knots. Effectiveness of the proposed methodology is illustrated using a few real-data examples.}
}

%%%%%%%
%%% P %%%
%%%%%%%

@article{Perron:2001,
	ISSN = {0006341X, 15410420},
	URL = {http://www.jstor.org/stable/3068361},
	abstract = {Nonparametric modeling is an indispensable tool in many applications and its formulation in an hierarchical Bayesian context, using the entire posterior distribution rather than particular expectations, increases its flexibility. In this article, the focus is on nonparametric estimation through a mixture of triangular distributions. The optimality of this methodology is addressed and bounds on the accuracy of this approximation are derived. Although our approach is more widely applicable, we focus for simplicity on estimation of a monotone nondecreasing regression on [0, 1] with additive error, effectively approximating the function of interest by a function having a piecewise linear derivative. Computationally accessible methods of estimation are described through an amalgamation of existing Markov chain Monte Carlo algorithms. Simulations and examples illustrate the approach.},
	author = {F. Perron and K. Mengersen},
	journal = {Biometrics},
	number = {2},
	pages = {518--528},
	publisher = {[Wiley, International Biometric Society]},
	title = {Bayesian Nonparametric Modeling Using Mixtures of Triangular Distributions},
	volume = {57},
	year = {2001}
}



@article{Petrone:1999a,
	author = {Petrone, Sonia},
	title = {{Random Bernstein Polynomials}},
	journal = {Scandinavian Journal of Statistics},
	volume = {26},
	number = {3},
	pages = {373-393},
	keywords = {Bayesian non-parametric inference, Bernstein polynomials, Dirichlet process, Markov chain Monte Carlo, random distribution functions},
	doi = {10.1111/1467-9469.00155},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9469.00155},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9469.00155},
abstract = {Random Bernstein polynomials which are also probability distribution functions on the closed unit interval are studied. The probability law of a Bernstein polynomial so defined provides a novel prior on the space of distribution functions on [0, 1] which has full support and can easily select absolutely continuous distribution functions with a continuous and smooth derivative. In particular, the Bernstein polynomial which approximates a Dirichlet process is studied. This may be of interest in Bayesian non-parametric inference. In the second part of the paper, we study the posterior from a “Bernstein–Dirichlet” prior and suggest a hybrid Monte Carlo approximation of it. The proposed algorithm has some aspects of novelty since the problem under examination has a “changing dimension” parameter space.},,
	year = {1999}
}

@article{Petrone:199b,
	ISSN = {03195724},
	URL = {http://www.jstor.org/stable/3315494},
	abstract = {We propose a Bayesian nonparametric procedure for density estimation, for data in a closed, bounded interval, say [0, 1]. To this aim, we use a prior based on Bernstein polynomials. This corresponds to expressing the density of the data as a mixture of given beta densities, with random weights and a random number of components. The density estimate is then obtained as the corresponding predictive density function. Comparison with classical and Bayesian kernel estimates is provided. The proposed procedure is illustrated in an example; an MCMC algorithm for approximating the estimate is also discussed. /// L'auteure propose une procédure bayésienne non paramétrique pour l'estimation de la densité à partir de données appartenant à un intervalle fermé et borné tel que l'intervalle [0, 1]. Dans ce but, elle fait appel à une loi a priori construite à partir des polynômes de Bernstein. Ceci revient à exprimer la densité des observations par un mélange d'un nombre aléatoire de densités bêta particulières affectées de poids aléatoires. C'est alors la densité prédictive correspondante qui sert d'estimateur. L'auteure compare celui-ci aux estimations à noyau classiques et de Bayes. Cette technique d'estimation est illustrée à l'aide d'un exemple et l'auteure montre comment approximer la solution au moyen d'un algorithme de Monte-Carlo à chaîne de Markov.},
	author = {Sonia Petrone},
	journal = {The Canadian Journal of Statistics / La Revue Canadienne de Statistique},
	number = {1},
	pages = {105--126},
	publisher = {[Statistical Society of Canada, Wiley]},
	title = {Bayesian Density Estimation Using Bernstein Polynomials},
	volume = {27},
	year = {1999}
}



%%%%%%%
%%% R %%%
%%%%%%%

@article{Ruppert2002,
	author = {David Ruppert},
	title = {Selecting the Number of Knots for Penalized Splines},
	journal = {Journal of Computational and Graphical Statistics},
	volume = {11},
	number = {4},
	pages = {735-757},
	year  = {2002},
	publisher = {Taylor & Francis},
	doi = {10.1198/106186002853},
	URL = {https://doi.org/10.1198/106186002853},
	eprint = {https://doi.org/10.1198/106186002853}
}

%%%%%%%
%%% S %%%
%%%%%%%

@article{Sethuraman:1994,
	added-at = {2009-09-10T14:36:22.000+0200},
	author = {Sethuraman, Jayaram},
	biburl = {https://www.bibsonomy.org/bibtex/2a7d63ad6a7d9bdcc2a6a1a3032863e7e/gregoryy},
	interhash = {4fcacac17864e008a908928ef7091141},
	intrahash = {a7d63ad6a7d9bdcc2a6a1a3032863e7e},
	journal = {Statistica Sinica},
	keywords = {imported},
	owner = {heinrich},
	pages = {639-650},
	timestamp = {2009-09-10T14:36:48.000+0200},
	title = {A constructive definition of {Dirichlet} priors},
	volume = 4,
	year = 1994
}

%%%%%%%
%%% W %%%
%%%%%%%

@article{Whittle:1957,
	ISSN = {00359246},
	URL = {http://www.jstor.org/stable/2983994},
	abstract = {The difficulty in constructing smoothing formulae is to express quantitatively the type of smoothness one expects of the curve one is estimating. An argument is given in Sections 1 and 3 for formulating this "smoothness hypothesis" in terms of the properties of a population of curves of which the curve being estimated is a member. In equation (20) we obtain a solution for the matrix of optimum weighting coefficients in terms of certain "population moments" of the ordinates of the curve. Explicit formulae based on special assumptions are deduced in equations (34), (56)-(58). General information is gained on the way the optimum smoothing function and the variance of the smoothed estimate vary with the sample size and with the assumed degree of smoothness of the parent curve.},
	author = {P. Whittle},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	number = {1},
	pages = {38--63},
	publisher = {[Royal Statistical Society, Wiley]},
	title = {Curve and Periodogram Smoothing},
	volume = {19},
	year = {1957}
}

